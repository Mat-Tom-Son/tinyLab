\section{Discussion and Limitations}

\paragraph{Scope of explanation.}
Suppressors account for a large share of factual degradation, but not all hallucinations.
Long-context failures, decoder sampling artifacts, and post-training alignment updates introduce additional pathways to error.
Our results therefore identify a \emph{primary} mechanism, not an exhaustive catalogue.

\paragraph{Scale and coverage.}
We studied GPT-2 Medium and Mistral-7B.
Larger models may migrate suppressor functionality to deeper layers or distribute it across more heads.
Mapping suppressors across GPT-3, Llama, Pythia, Qwen, and other families is necessary before claiming full universality.

\paragraph{Training dynamics.}
We observe suppressors in fully-trained networks but did not instrument training.
It remains unknown when suppressors crystallise, whether they emerge gradually or via abrupt phase transitions, and how alternative objectives (e.g.\ DPO, constitutional AI) modify them.

\paragraph{Single-seed Mistral results.}
Mistral experiments currently rely on seed~0 due to compute constraints.
While the signal is strong, multi-seed replication is queued to quantify variance and confirm stability.

\paragraph{Threats to validity.}
All experiments use deterministic Apple M-series (MPS) kernels; while we observed identical seeds across runs, CUDA backends may introduce numerical drift. Mistral results currently use a single seed, and we rely on byte-pair token cleanup when constructing the hedge/booster lexicon, so residual tokenization artifacts may remain. Finally, the probe suite covers single-token judgments; multi-token generation may surface additional suppressor interactions.
