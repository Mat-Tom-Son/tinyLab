\section{Cross-Architecture Validation}
\label{sec:cross_arch}

Section~\ref{sec:case_study} demonstrated that the L0 hedging coalition survives TinyLab's methodological tests in GPT-2 Medium. This section tests \textbf{cross-architecture generalization}: does the hedging motif appear in other model families despite architectural differences? If the coalition is a genuine learned behavioral prior (arising from gradient descent under binary evaluation), it should replicate across architectures, though implementations may differ.

We validate across three models:
\begin{itemize}
    \item \textbf{GPT-2 Small (124M):} 12 layers, 12 heads/layer, standard multi-head attention (MHA)
    \item \textbf{GPT-2 Medium (355M):} 24 layers, 16 heads/layer, MHA
    \item \textbf{Mistral-7B (7B):} 32 layers, 32 heads/layer, grouped-query attention (GQA), sliding window
\end{itemize}

\subsection{GPT-2 Small $\to$ Medium: Conservation}

\paragraph{Hypothesis.}

If the hedging coalition is architectural (not learned), it should appear at the same \textit{relative} positions across model scales within the GPT-2 family.

\paragraph{Method.}

Run H1 battery on GPT-2 Small using identical probe suite (facts, negation, counterfactual, logic). Compare head rankings to GPT-2 Medium.

\paragraph{Results.}

Table~\ref{tab:gpt2_conservation} shows the top-3 layer-0 heads for both models.

\begin{table}[t]
\centering
\caption{Conservation Across GPT-2 Scale (L0 Heads, Mean $\Delta$LD Across Tasks)}
\label{tab:gpt2_conservation}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Head 1} & \textbf{Head 2} & \textbf{Head 3} & \textbf{Rank Correlation $\rho$} \\
\midrule
GPT-2 Small (124M)  & 0:2 (+0.38) & 0:4 (+0.12) & 0:7 (+0.11) & — \\
GPT-2 Medium (355M) & 0:2 (+0.41) & 0:4 (+0.13) & 0:7 (+0.12) & $\rho = 0.94$ \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Interpretation.}

\begin{itemize}
    \item \textbf{Exact conservation:} Identical heads \{0:2, 0:4, 0:7\} in both models
    \item \textbf{Nearly identical effect sizes:} GPT-2 Small head~0:2 $\Delta$LD $= +0.38$ vs. Medium $+0.41$ (7\% difference)
    \item \textbf{High rank correlation:} $\rho = 0.94$ between head rankings across models
\end{itemize}

\textbf{Conclusion:} The hedging coalition is \textbf{conserved} across GPT-2 scale. This rules out ``checkpoint fluke'' and suggests an architectural prior encoded during training.

\subsection{GPT-2 $\to$ Mistral: Adapted Motif}

\paragraph{Challenge.}

Mistral-7B differs from GPT-2 in multiple dimensions:
\begin{itemize}
    \item \textbf{Architecture:} Grouped-query attention (GQA) vs. standard MHA; sliding window attention vs. full attention
    \item \textbf{Scale:} 32~layers vs. 24; 32~heads/layer vs. 16
    \item \textbf{Tokenizer:} SentencePiece vs. BPE (requires dataset adaptation)
    \item \textbf{Training:} Different corpus, optimization hyperparameters
\end{itemize}

If the hedging motif is a learned behavioral prior (not architectural), Mistral should discover a \textbf{variant}: different heads, same function.

\paragraph{Method.}

Run H1 battery on Mistral-7B with tokenizer-adapted probe suite. Identify layer-0 heads whose ablation improves $\Delta$LD, similar to GPT-2's coalition.

\paragraph{Results: Task-Contingent Coalition.}

Table~\ref{tab:mistral_coalition} shows Mistral's top layer-0 heads across tasks.

\begin{table}[t]
\centering
\caption{Mistral-7B L0 Coalition: Head Impact by Task (Single-Seed Estimates)}
\label{tab:mistral_coalition}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Head} & \textbf{Facts} & \textbf{Negation} & \textbf{Counterfactual} & \textbf{Logic} \\
\midrule
0:22 & -0.001 & +0.118 & +0.155 & -0.021 \\
0:23 & +0.002 & +0.107 & +0.127 & -0.021 \\
0:21 & +0.006 & +0.015 & +0.003 & \textbf{-0.390} \\
\midrule
\textbf{Pair \{0:22, 0:23\}} & -0.003 & +0.225 & +0.282 & -0.042 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key Observations.}

\begin{enumerate}
    \item \textbf{Coalition exists:} Heads \{0:22, 0:23\} show hedging behavior (ablation improves $\Delta$LD) on negation/counterfactual tasks
    \item \textbf{Task-contingent:} Coalition has \textit{minimal} effect on facts ($\Delta$LD $\approx 0$), unlike GPT-2's universal suppression
    \item \textbf{Opposition mechanism:} Head~0:21 \textit{opposes} the coalition on logic tasks ($\Delta$LD $= -0.39$ when ablated alone), suggesting task-specific modulation
    \item \textbf{No hedging boost:} OV analysis (Table~\ref{tab:mistral_ov}) shows \{0:22, 0:23\} lack GPT-2's hedge/booster enrichment; instead surface editorial tokens
\end{enumerate}

\subsection{Mistral OV Analysis: Editorial, Not Hedging}

\paragraph{Question.}

Does Mistral's coalition upweight hedge/booster vocabulary like GPT-2's head~0:2?

\paragraph{Method.}

Extract OV directions for heads~\{0:22, 0:23\}, project onto vocabulary, compare to hedge/booster lexicon.

\paragraph{Results.}

\begin{table}[t]
\centering
\caption{Mistral L0 Coalition: Representative OV Tokens (Heads 0:22, 0:23)}
\label{tab:mistral_ov}
\small
\begin{tabular}{lll}
\toprule
\textbf{Head} & \textbf{Upweighted Tokens} & \textbf{Downweighted Tokens} \\
\midrule
0:22 & giornata, listade, acknow & oppon, LIED, itself \\
0:23 & acknow, d\'{e}part, kat & ionato, altogether, strict \\
\midrule
\multicolumn{3}{l}{\textit{Lexicon enrichment: Hedges/Boosters $\approx 0$ log-odds (no signal)}} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Interpretation.}

\begin{itemize}
    \item \textbf{No hedging vocabulary:} Mistral's coalition does \textit{not} upweight ``perhaps,'' ``maybe,'' ``seems''
    \item \textbf{Editorial fragments:} Instead surfaces multilingual tokens (``giornata,'' ``d\'{e}part''), acknowledgment fragments (``acknow''), and factual opposites (``LIED,'' ``oppon'')
    \item \textbf{Functional divergence:} Mistral's coalition suppresses factual continuations (like GPT-2) but lacks the hedge-amplification component
\end{itemize}

\textbf{Conclusion:} Mistral learns an \textbf{adapted variant} of the hedging motif—factual suppression without hedging boost—suggesting the core function (trading factuality) is conserved but implementation details differ.

\subsection{Opposition Mechanism: Head 0:21 as Anti-Coalition}

\paragraph{Observation.}

Head~0:21 shows \textit{negative} $\Delta$LD when ablated on logic tasks ($-0.39$), meaning its removal \textit{degrades} factual preference. This opposes the coalition's suppressive effect.

\paragraph{H5 Competition Test.}

We run pair ablation \{0:21, 0:22\} to test whether head~0:21 counteracts head~0:22's suppression.

\paragraph{Results.}

\begin{table}[t]
\centering
\caption{Mistral Opposition Mechanism: Head 0:21 vs. Coalition (Logic Probe)}
\label{tab:mistral_opposition}
\small
\begin{tabular}{lcc}
\toprule
\textbf{Ablation} & \textbf{$\Delta$LD (Logic)} & \textbf{Interpretation} \\
\midrule
0:21 alone & -0.390 & Anti-coalition (removal hurts) \\
0:22 alone & -0.021 & Weak suppression \\
\midrule
Pair \{0:21, 0:22\} & -0.411 & Net effect: sum of individual \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Interpretation.}

\begin{itemize}
    \item \textbf{Opposition on logic:} Head~0:21 \textit{counteracts} coalition suppression on logic tasks
    \item \textbf{Task-specific modulation:} Mistral's layer-0 includes both suppressive (\{0:22, 0:23\}) and anti-suppressive (0:21) heads, with task-contingent activation
    \item \textbf{Architectural adaptation:} GPT-2 learns a \textit{universal} coalition; Mistral learns a \textit{modulated} coalition with internal opposition
\end{itemize}

\subsection{Invariants Analysis: What Is Conserved?}

\paragraph{Question.}

Across GPT-2 Small, Medium, and Mistral, what components are \textbf{invariant} (appear in all models)?

\paragraph{Method.}

\begin{enumerate}
    \item For each model, compute top-10 heads per task (by $\Delta$LD)
    \item Find intersection across all three models and all four tasks
    \item Report conserved layer positions, if any
\end{enumerate}

\paragraph{Results.}

\begin{table}[t]
\centering
\caption{Cross-Architecture Invariants (Top-10 Heads per Task, Intersection)}
\label{tab:invariants}
\small
\begin{tabular}{lll}
\toprule
\textbf{Model} & \textbf{Conserved Heads} & \textbf{Conserved Layers} \\
\midrule
GPT-2 Small & \{0:2, 0:4, 0:7\} & \{0, 11\} \\
GPT-2 Medium & \{0:2, 0:4, 0:7\} & \{0, 11\} \\
Mistral-7B & \{0:22, 0:23\} & \{0\} \\
\midrule
\textbf{Intersection (all models)} & — & \textbf{\{0\}} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Interpretation.}

\begin{itemize}
    \item \textbf{Layer-0 is universal:} All three models show early-layer hedging behavior (specific heads differ, but layer~0 is conserved)
    \item \textbf{Head positions vary:} GPT-2 uses \{0:2, 0:4, 0:7\}; Mistral uses \{0:22, 0:23\}
    \item \textbf{Mid-layer mediation varies:} GPT-2 routes through layer~11; Mistral's mediation structure unknown (future H6 work)
\end{itemize}

\textbf{Conclusion:} The \textbf{motif} (early-layer hedging) is conserved across architectures. The \textbf{implementation} (specific heads, mid-layer paths, hedge-boosting vs. editorial) adapts to architecture.

\subsection{Single-Seed Limitation and Multi-Seed Plan}

\paragraph{Acknowledgment.}

Mistral results currently use single-seed estimates (seed~0) due to compute constraints. Seeds~\{1, 2\} on negation/counterfactual tasks reproduce seed~0 exactly (95\% CI $\approx 0$ due to MPS determinism), but broader seed sweeps across all tasks are queued.

\paragraph{Mitigation.}

\begin{itemize}
    \item Effect sizes are large ($\Delta$LD $> 0.1$ on negation/counterfactual)
    \item Deterministic MPS reproduction suggests low variance
    \item Random baseline comparison planned (1,000~random L0 Mistral ablations) to contextualize percentile ranking
\end{itemize}

Multi-seed Mistral sweeps are documented in the reproducibility roadmap (Appendix~B).

\subsection{Summary: Hedging Motif Is Learned, Implementation Adapts}

Cross-architecture validation demonstrates:

\begin{enumerate}
    \item \textbf{Conservation (GPT-2 Small $\to$ Medium):} Identical heads \{0:2, 0:4, 0:7\}, nearly identical effect sizes ($\rho = 0.94$)
    \item \textbf{Adaptation (GPT-2 $\to$ Mistral):} Different heads (\{0:22, 0:23\}), task-contingent activation, opposition mechanism (head~0:21), no hedging boost
    \item \textbf{Universal motif:} Layer-0 hedging behavior appears in all three models despite architectural differences (MHA vs. GQA, 124M vs. 7B parameters)
\end{enumerate}

This validates the hedging coalition as a \textbf{learned behavioral prior}: gradient descent repeatedly discovers early-layer circuits that trade factuality for hedging under binary evaluation, but architectural constraints shape the specific implementation. The motif is not an artifact of GPT-2's architecture; it is a stable solution to conflicting training objectives.

Next, we discuss implications, limitations, and future directions (Section~\ref{sec:discussion}).
